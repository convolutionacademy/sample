{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25c1a38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8e1012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MovieLens dataset\n",
    "df_ratings = pd.read_csv('ml-latest-small/ratings.csv')\n",
    "df_movies = pd.read_csv('ml-latest-small/movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465d5ba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb7a76b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0d00cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "df_ratings = df_ratings[['userId', 'movieId', 'rating']]\n",
    "df_movies = df_movies[['movieId', 'title', 'genres']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87d27d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Merge ratings and movies data\n",
    "df_merged = pd.merge(df_ratings, df_movies, on='movieId')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eb84275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating             title  \\\n",
       "0       1        1     4.0  Toy Story (1995)   \n",
       "1       5        1     4.0  Toy Story (1995)   \n",
       "2       7        1     4.5  Toy Story (1995)   \n",
       "3      15        1     2.5  Toy Story (1995)   \n",
       "4      17        1     4.5  Toy Story (1995)   \n",
       "5      18        1     3.5  Toy Story (1995)   \n",
       "6      19        1     4.0  Toy Story (1995)   \n",
       "7      21        1     3.5  Toy Story (1995)   \n",
       "8      27        1     3.0  Toy Story (1995)   \n",
       "9      31        1     5.0  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "5  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "6  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "7  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "8  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "9  Adventure|Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6ed2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(range(1,20))\n",
    "df_merged_t = df_merged.query(f'userId in {ids}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2fe8fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_movie_id = df_merged_t['movieId'].drop_duplicates().reset_index(drop=True).reset_index()\n",
    "df_merged_movie_id.rename(columns={'index':'newmovie_id'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd8a39b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_t = pd.merge(df_merged_t,df_merged_movie_id,how='inner',on='movieId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa22d21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2977, 6)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd37ed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split dataset into train and test\n",
    "train_data, test_data = train_test_split(df_merged_t, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "854989ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4e7b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize movie titles\n",
    "train_tokens = tokenizer.batch_encode_plus(\n",
    "    train_data['title'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='np',\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "182c8916",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tokens = tokenizer.batch_encode_plus(\n",
    "    test_data['title'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    return_tensors='np',\n",
    "    max_length=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce1fbf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare CF input data\n",
    "train_user_ids = train_data['userId'].values\n",
    "train_item_ids = train_data['newmovie_id'].values\n",
    "train_ratings = train_data['rating'].values\n",
    "\n",
    "test_user_ids = test_data['userId'].values\n",
    "test_item_ids = test_data['newmovie_id'].values\n",
    "test_ratings = test_data['rating'].values\n",
    "\n",
    "# Prepare BERT input data\n",
    "train_input_ids = train_tokens['input_ids']\n",
    "train_attention_mask = train_tokens['attention_mask']\n",
    "\n",
    "test_input_ids = test_tokens['input_ids']\n",
    "test_attention_mask = test_tokens['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f889d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea407459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types\n",
    "train_user_ids = train_user_ids.astype(np.int32)\n",
    "train_item_ids = train_item_ids.astype(np.int32)\n",
    "train_ratings = train_ratings.astype(np.float32)\n",
    "\n",
    "test_user_ids = test_user_ids.astype(np.int32)\n",
    "test_item_ids = test_item_ids.astype(np.int32)\n",
    "test_ratings = test_ratings.astype(np.float32)\n",
    "\n",
    "train_input_ids = train_input_ids.astype(np.int32)\n",
    "train_attention_mask = train_attention_mask.astype(np.int32)\n",
    "\n",
    "test_input_ids = test_input_ids.astype(np.int32)\n",
    "test_attention_mask = test_attention_mask.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "713b8591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19e15c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a5312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Define CF Model\n",
    "class CFModel(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim):\n",
    "        super(CFModel, self).__init__()\n",
    "        self.user_embeddings = tf.keras.layers.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = tf.keras.layers.Embedding(num_items, embedding_dim)\n",
    "        self.fc1 = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.fc2 = tf.keras.layers.Dense(embedding_dim)\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_embeds = self.user_embeddings(user_ids)\n",
    "        item_embeds = self.item_embeddings(item_ids)\n",
    "        user_embeds = self.relu(self.fc1(user_embeds))\n",
    "        item_embeds = self.relu(self.fc2(item_embeds))\n",
    "        return user_embeds, item_embeds\n",
    "\n",
    "# Define CF HybridBERT4Rec model\n",
    "class CFHybridBERT4Rec(tf.keras.Model):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, bert_model):\n",
    "        super(CFHybridBERT4Rec, self).__init__()\n",
    "        self.cf_model = CFModel(num_users, num_items, embedding_dim)\n",
    "        self.bert_model = bert_model\n",
    "        self.fc = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, user_ids, item_ids, input_ids, attention_mask):\n",
    "        user_embeds, item_embeds = self.cf_model(user_ids, item_ids)\n",
    "        bert_outputs = self.bert_model(input_ids, attention_mask=attention_mask)[1]  # Pooled output\n",
    "        combined_embeds = tf.concat([user_embeds, item_embeds, bert_outputs], axis=1)\n",
    "        logits = self.fc(combined_embeds)\n",
    "        return tf.squeeze(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "395001ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b29dc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_users = df_ratings['userId'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0835b017",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create an instance of the CFHybridBERT4Rec model\n",
    "num_users = df_ratings['userId'].nunique()\n",
    "num_items = df_ratings['movieId'].nunique()\n",
    "embedding_dim = 32\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "hybrid_model = CFHybridBERT4Rec(num_users+1, num_items, embedding_dim, bert_model)\n",
    "\n",
    "# Training loop\n",
    "num_batches = len(train_user_ids) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dad436a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d1f5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.26743969321250916\n",
      "Epoch 1/10, Loss: 0.3394688665866852\n",
      "Epoch 1/10, Loss: 0.4371115267276764\n",
      "Epoch 1/10, Loss: 0.4605918526649475\n",
      "Epoch 1/10, Loss: 0.5465521812438965\n",
      "Epoch 1/10, Loss: 0.5607895255088806\n",
      "Epoch 1/10, Loss: 0.5848242044448853\n",
      "Epoch 1/10, Loss: 0.661707878112793\n",
      "Epoch 1/10, Loss: 0.6872411966323853\n",
      "Epoch 1/10, Loss: 0.7011879086494446\n",
      "Epoch 1/10, Loss: 0.7299047708511353\n",
      "Epoch 1/10, Loss: 0.7595760226249695\n",
      "Epoch 1/10, Loss: 0.7796232104301453\n",
      "Epoch 1/10, Loss: 0.7930862307548523\n",
      "Epoch 1/10, Loss: 0.8119447231292725\n",
      "Epoch 1/10, Loss: 0.8244717121124268\n",
      "Epoch 1/10, Loss: 0.8392448425292969\n",
      "Epoch 1/10, Loss: 0.8555927872657776\n",
      "Epoch 1/10, Loss: 0.8750709295272827\n",
      "Epoch 1/10, Loss: 0.8987287282943726\n",
      "Epoch 1/10, Loss: 0.9205418229103088\n",
      "Epoch 1/10, Loss: 0.9355074167251587\n",
      "Epoch 1/10, Loss: 0.9557492136955261\n",
      "Epoch 1/10, Loss: 0.970703125\n",
      "Epoch 1/10, Loss: 0.9793684482574463\n",
      "Epoch 1/10, Loss: 0.9949675798416138\n",
      "Epoch 1/10, Loss: 1.0086506605148315\n",
      "Epoch 1/10, Loss: 1.0259971618652344\n",
      "Epoch 1/10, Loss: 1.0419864654541016\n",
      "Epoch 1/10, Loss: 1.0534573793411255\n",
      "Epoch 1/10, Loss: 1.072513222694397\n",
      "Epoch 1/10, Loss: 1.0859251022338867\n",
      "Epoch 1/10, Loss: 1.1033159494400024\n",
      "Epoch 1/10, Loss: 1.1290929317474365\n",
      "Epoch 1/10, Loss: 1.1448863744735718\n",
      "Epoch 1/10, Loss: 1.1697684526443481\n",
      "Epoch 1/10, Loss: 1.1884663105010986\n",
      "Epoch 1/10, Loss: 1.2051820755004883\n",
      "Epoch 1/10, Loss: 1.2246955633163452\n",
      "Epoch 1/10, Loss: 1.2424333095550537\n",
      "Epoch 1/10, Loss: 1.2625935077667236\n",
      "Epoch 1/10, Loss: 1.2750638723373413\n",
      "Epoch 1/10, Loss: 1.295986533164978\n",
      "Epoch 1/10, Loss: 1.3131084442138672\n",
      "Epoch 1/10, Loss: 1.3332065343856812\n",
      "Epoch 1/10, Loss: 1.3508775234222412\n",
      "Epoch 1/10, Loss: 1.3669697046279907\n",
      "Epoch 1/10, Loss: 1.3793206214904785\n",
      "Epoch 1/10, Loss: 1.389158010482788\n",
      "Epoch 1/10, Loss: 1.4032201766967773\n",
      "Epoch 1/10, Loss: 1.421889066696167\n",
      "Epoch 1/10, Loss: 1.444570541381836\n",
      "Epoch 1/10, Loss: 1.4565483331680298\n",
      "Epoch 1/10, Loss: 1.472555160522461\n",
      "Epoch 1/10, Loss: 1.4913456439971924\n",
      "Epoch 1/10, Loss: 1.5113790035247803\n",
      "Epoch 1/10, Loss: 1.532961368560791\n",
      "Epoch 1/10, Loss: 1.5548220872879028\n",
      "Epoch 1/10, Loss: 1.5702319145202637\n",
      "Epoch 1/10, Loss: 1.5837275981903076\n",
      "Epoch 1/10, Loss: 1.60123872756958\n",
      "Epoch 1/10, Loss: 1.619365930557251\n",
      "Epoch 1/10, Loss: 1.6281213760375977\n",
      "Epoch 1/10, Loss: 1.6473749876022339\n",
      "Epoch 1/10, Loss: 1.6603249311447144\n",
      "Epoch 1/10, Loss: 1.6768512725830078\n",
      "Epoch 1/10, Loss: 1.6955935955047607\n",
      "Epoch 1/10, Loss: 1.7208377122879028\n",
      "Epoch 1/10, Loss: 1.7321265935897827\n",
      "Epoch 1/10, Loss: 1.750436544418335\n",
      "Epoch 1/10, Loss: 1.766563057899475\n",
      "Epoch 1/10, Loss: 1.7862720489501953\n",
      "Epoch 1/10, Loss: 1.8024622201919556\n",
      "Epoch 1/10, Loss: 1.8179867267608643\n",
      "Epoch 2/10, Loss: 0.01719638518989086\n",
      "Epoch 2/10, Loss: 0.02756313979625702\n",
      "Epoch 2/10, Loss: 0.04062885046005249\n",
      "Epoch 2/10, Loss: 0.0558905228972435\n",
      "Epoch 2/10, Loss: 0.0792805403470993\n",
      "Epoch 2/10, Loss: 0.09207430481910706\n",
      "Epoch 2/10, Loss: 0.11474448442459106\n",
      "Epoch 2/10, Loss: 0.1310911923646927\n",
      "Epoch 2/10, Loss: 0.1562013328075409\n",
      "Epoch 2/10, Loss: 0.16889818012714386\n",
      "Epoch 2/10, Loss: 0.18631792068481445\n",
      "Epoch 2/10, Loss: 0.20750539004802704\n",
      "Epoch 2/10, Loss: 0.22666305303573608\n",
      "Epoch 2/10, Loss: 0.24031272530555725\n",
      "Epoch 2/10, Loss: 0.2530306279659271\n",
      "Epoch 2/10, Loss: 0.265277624130249\n",
      "Epoch 2/10, Loss: 0.27901291847229004\n",
      "Epoch 2/10, Loss: 0.2907082438468933\n",
      "Epoch 2/10, Loss: 0.3128671646118164\n",
      "Epoch 2/10, Loss: 0.3390132486820221\n",
      "Epoch 2/10, Loss: 0.3596429228782654\n",
      "Epoch 2/10, Loss: 0.3743617832660675\n",
      "Epoch 2/10, Loss: 0.39260685443878174\n",
      "Epoch 2/10, Loss: 0.40589189529418945\n",
      "Epoch 2/10, Loss: 0.41608911752700806\n",
      "Epoch 2/10, Loss: 0.42777758836746216\n",
      "Epoch 2/10, Loss: 0.4398368000984192\n",
      "Epoch 2/10, Loss: 0.45672523975372314\n",
      "Epoch 2/10, Loss: 0.47172462940216064\n",
      "Epoch 2/10, Loss: 0.4820139706134796\n",
      "Epoch 2/10, Loss: 0.4991896450519562\n",
      "Epoch 2/10, Loss: 0.511224627494812\n",
      "Epoch 2/10, Loss: 0.5285502076148987\n",
      "Epoch 2/10, Loss: 0.5563701391220093\n",
      "Epoch 2/10, Loss: 0.5726408958435059\n",
      "Epoch 2/10, Loss: 0.590255618095398\n",
      "Epoch 2/10, Loss: 0.6044024229049683\n",
      "Epoch 2/10, Loss: 0.6201573014259338\n",
      "Epoch 2/10, Loss: 0.6403717398643494\n",
      "Epoch 2/10, Loss: 0.6541391611099243\n",
      "Epoch 2/10, Loss: 0.6704307794570923\n",
      "Epoch 2/10, Loss: 0.679076075553894\n",
      "Epoch 2/10, Loss: 0.6971113085746765\n",
      "Epoch 2/10, Loss: 0.7080315351486206\n",
      "Epoch 2/10, Loss: 0.7240743637084961\n",
      "Epoch 2/10, Loss: 0.7406572103500366\n",
      "Epoch 2/10, Loss: 0.7573688626289368\n",
      "Epoch 2/10, Loss: 0.7663264274597168\n",
      "Epoch 2/10, Loss: 0.7743086814880371\n",
      "Epoch 2/10, Loss: 0.7862949371337891\n",
      "Epoch 2/10, Loss: 0.8013489246368408\n",
      "Epoch 2/10, Loss: 0.8228055834770203\n",
      "Epoch 2/10, Loss: 0.8326999545097351\n",
      "Epoch 2/10, Loss: 0.8465079665184021\n",
      "Epoch 2/10, Loss: 0.8636711835861206\n",
      "Epoch 2/10, Loss: 0.8819577097892761\n",
      "Epoch 2/10, Loss: 0.8980177044868469\n",
      "Epoch 2/10, Loss: 0.9175573587417603\n",
      "Epoch 2/10, Loss: 0.9330625534057617\n",
      "Epoch 2/10, Loss: 0.9432533979415894\n",
      "Epoch 2/10, Loss: 0.9559924006462097\n",
      "Epoch 2/10, Loss: 0.9700828790664673\n",
      "Epoch 2/10, Loss: 0.9777898192405701\n",
      "Epoch 2/10, Loss: 0.9926490783691406\n",
      "Epoch 2/10, Loss: 1.0038783550262451\n",
      "Epoch 2/10, Loss: 1.0155386924743652\n",
      "Epoch 2/10, Loss: 1.028866171836853\n",
      "Epoch 2/10, Loss: 1.0488073825836182\n",
      "Epoch 2/10, Loss: 1.0563114881515503\n",
      "Epoch 2/10, Loss: 1.0668607950210571\n",
      "Epoch 2/10, Loss: 1.0800608396530151\n",
      "Epoch 2/10, Loss: 1.0939407348632812\n",
      "Epoch 2/10, Loss: 1.1045339107513428\n",
      "Epoch 2/10, Loss: 1.1135207414627075\n",
      "Epoch 3/10, Loss: 0.009933116845786572\n",
      "Epoch 3/10, Loss: 0.01597677543759346\n",
      "Epoch 3/10, Loss: 0.02456037327647209\n",
      "Epoch 3/10, Loss: 0.0363299585878849\n",
      "Epoch 3/10, Loss: 0.05305511876940727\n",
      "Epoch 3/10, Loss: 0.059930723160505295\n",
      "Epoch 3/10, Loss: 0.07485290616750717\n",
      "Epoch 3/10, Loss: 0.08587566018104553\n",
      "Epoch 3/10, Loss: 0.10766289383172989\n",
      "Epoch 3/10, Loss: 0.11670929938554764\n",
      "Epoch 3/10, Loss: 0.13406962156295776\n",
      "Epoch 3/10, Loss: 0.1478745937347412\n",
      "Epoch 3/10, Loss: 0.15789100527763367\n",
      "Epoch 3/10, Loss: 0.1661243885755539\n",
      "Epoch 3/10, Loss: 0.17588157951831818\n",
      "Epoch 3/10, Loss: 0.1866443157196045\n",
      "Epoch 3/10, Loss: 0.19664372503757477\n",
      "Epoch 3/10, Loss: 0.2043599635362625\n",
      "Epoch 3/10, Loss: 0.21862301230430603\n",
      "Epoch 3/10, Loss: 0.23444320261478424\n",
      "Epoch 3/10, Loss: 0.24939784407615662\n",
      "Epoch 3/10, Loss: 0.2621181607246399\n",
      "Epoch 3/10, Loss: 0.2772640585899353\n",
      "Epoch 3/10, Loss: 0.2883436679840088\n",
      "Epoch 3/10, Loss: 0.2927706837654114\n",
      "Epoch 3/10, Loss: 0.2991558015346527\n",
      "Epoch 3/10, Loss: 0.30884748697280884\n",
      "Epoch 3/10, Loss: 0.32595381140708923\n",
      "Epoch 3/10, Loss: 0.33939844369888306\n",
      "Epoch 3/10, Loss: 0.3486262857913971\n",
      "Epoch 3/10, Loss: 0.36250486969947815\n",
      "Epoch 3/10, Loss: 0.37150219082832336\n",
      "Epoch 3/10, Loss: 0.3841140568256378\n",
      "Epoch 3/10, Loss: 0.40458622574806213\n",
      "Epoch 3/10, Loss: 0.4192720651626587\n",
      "Epoch 3/10, Loss: 0.43146446347236633\n",
      "Epoch 3/10, Loss: 0.4413725733757019\n",
      "Epoch 3/10, Loss: 0.45225340127944946\n",
      "Epoch 3/10, Loss: 0.4667467772960663\n",
      "Epoch 3/10, Loss: 0.4785837233066559\n",
      "Epoch 3/10, Loss: 0.4908443093299866\n",
      "Epoch 3/10, Loss: 0.49804332852363586\n",
      "Epoch 3/10, Loss: 0.5129685997962952\n",
      "Epoch 3/10, Loss: 0.521027684211731\n",
      "Epoch 3/10, Loss: 0.5334017276763916\n",
      "Epoch 3/10, Loss: 0.5462927222251892\n",
      "Epoch 3/10, Loss: 0.5596477389335632\n",
      "Epoch 3/10, Loss: 0.5661798715591431\n",
      "Epoch 3/10, Loss: 0.5737251043319702\n",
      "Epoch 3/10, Loss: 0.584385097026825\n",
      "Epoch 3/10, Loss: 0.5969593524932861\n",
      "Epoch 3/10, Loss: 0.6148317456245422\n",
      "Epoch 3/10, Loss: 0.6221105456352234\n",
      "Epoch 3/10, Loss: 0.6336463689804077\n",
      "Epoch 3/10, Loss: 0.6498123407363892\n",
      "Epoch 3/10, Loss: 0.6657637357711792\n",
      "Epoch 3/10, Loss: 0.6787468791007996\n",
      "Epoch 3/10, Loss: 0.6949648261070251\n",
      "Epoch 3/10, Loss: 0.7095441222190857\n",
      "Epoch 3/10, Loss: 0.7171249985694885\n",
      "Epoch 3/10, Loss: 0.7270742058753967\n",
      "Epoch 3/10, Loss: 0.7380325198173523\n",
      "Epoch 3/10, Loss: 0.7453262805938721\n",
      "Epoch 3/10, Loss: 0.7553759813308716\n",
      "Epoch 3/10, Loss: 0.7632004022598267\n",
      "Epoch 3/10, Loss: 0.7708700299263\n",
      "Epoch 3/10, Loss: 0.7799925804138184\n",
      "Epoch 3/10, Loss: 0.7960836291313171\n",
      "Epoch 3/10, Loss: 0.8026841282844543\n",
      "Epoch 3/10, Loss: 0.8104737401008606\n",
      "Epoch 3/10, Loss: 0.8222483396530151\n",
      "Epoch 3/10, Loss: 0.8328981995582581\n",
      "Epoch 3/10, Loss: 0.8408063054084778\n",
      "Epoch 3/10, Loss: 0.8484911322593689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Loss: 0.006985940039157867\n",
      "Epoch 4/10, Loss: 0.011425546370446682\n",
      "Epoch 4/10, Loss: 0.01706700213253498\n",
      "Epoch 4/10, Loss: 0.02666308358311653\n",
      "Epoch 4/10, Loss: 0.04004381597042084\n",
      "Epoch 4/10, Loss: 0.04519251361489296\n",
      "Epoch 4/10, Loss: 0.05560368299484253\n",
      "Epoch 4/10, Loss: 0.06267324835062027\n",
      "Epoch 4/10, Loss: 0.0795220136642456\n",
      "Epoch 4/10, Loss: 0.0855463445186615\n",
      "Epoch 4/10, Loss: 0.0989343672990799\n",
      "Epoch 4/10, Loss: 0.10822919756174088\n",
      "Epoch 4/10, Loss: 0.11460883170366287\n",
      "Epoch 4/10, Loss: 0.11926297843456268\n",
      "Epoch 4/10, Loss: 0.1263536661863327\n",
      "Epoch 4/10, Loss: 0.13357987999916077\n",
      "Epoch 4/10, Loss: 0.13983219861984253\n",
      "Epoch 4/10, Loss: 0.14628556370735168\n",
      "Epoch 4/10, Loss: 0.15488360822200775\n",
      "Epoch 4/10, Loss: 0.16641803085803986\n",
      "Epoch 4/10, Loss: 0.17575794458389282\n",
      "Epoch 4/10, Loss: 0.18405325710773468\n",
      "Epoch 4/10, Loss: 0.19405801594257355\n",
      "Epoch 4/10, Loss: 0.20168693363666534\n",
      "Epoch 4/10, Loss: 0.20411410927772522\n",
      "Epoch 4/10, Loss: 0.20984117686748505\n",
      "Epoch 4/10, Loss: 0.2144959270954132\n",
      "Epoch 4/10, Loss: 0.22502285242080688\n",
      "Epoch 4/10, Loss: 0.23368977010250092\n",
      "Epoch 4/10, Loss: 0.24171069264411926\n",
      "Epoch 4/10, Loss: 0.2529812455177307\n",
      "Epoch 4/10, Loss: 0.2595347464084625\n",
      "Epoch 4/10, Loss: 0.2680369019508362\n",
      "Epoch 4/10, Loss: 0.28135085105895996\n",
      "Epoch 4/10, Loss: 0.2898577153682709\n",
      "Epoch 4/10, Loss: 0.29747867584228516\n",
      "Epoch 4/10, Loss: 0.30340224504470825\n",
      "Epoch 4/10, Loss: 0.3088383674621582\n",
      "Epoch 4/10, Loss: 0.3206638693809509\n",
      "Epoch 4/10, Loss: 0.329778254032135\n",
      "Epoch 4/10, Loss: 0.3357527554035187\n",
      "Epoch 4/10, Loss: 0.34041956067085266\n",
      "Epoch 4/10, Loss: 0.3546364903450012\n",
      "Epoch 4/10, Loss: 0.36166930198669434\n",
      "Epoch 4/10, Loss: 0.36989152431488037\n",
      "Epoch 4/10, Loss: 0.37962237000465393\n",
      "Epoch 4/10, Loss: 0.38748249411582947\n",
      "Epoch 4/10, Loss: 0.3935810327529907\n",
      "Epoch 4/10, Loss: 0.4027230739593506\n",
      "Epoch 4/10, Loss: 0.41185542941093445\n",
      "Epoch 4/10, Loss: 0.4275679290294647\n",
      "Epoch 4/10, Loss: 0.4406278431415558\n",
      "Epoch 4/10, Loss: 0.4455394744873047\n",
      "Epoch 4/10, Loss: 0.4523788094520569\n",
      "Epoch 4/10, Loss: 0.4623177647590637\n",
      "Epoch 4/10, Loss: 0.47607845067977905\n",
      "Epoch 4/10, Loss: 0.48827028274536133\n",
      "Epoch 4/10, Loss: 0.5005279779434204\n",
      "Epoch 4/10, Loss: 0.5143347382545471\n",
      "Epoch 4/10, Loss: 0.5193957686424255\n",
      "Epoch 4/10, Loss: 0.5269370675086975\n",
      "Epoch 4/10, Loss: 0.533716082572937\n",
      "Epoch 4/10, Loss: 0.5399580001831055\n",
      "Epoch 4/10, Loss: 0.5482011437416077\n",
      "Epoch 4/10, Loss: 0.5549346208572388\n",
      "Epoch 4/10, Loss: 0.5623530149459839\n",
      "Epoch 4/10, Loss: 0.5669721961021423\n",
      "Epoch 4/10, Loss: 0.5769798159599304\n",
      "Epoch 4/10, Loss: 0.5853157043457031\n",
      "Epoch 4/10, Loss: 0.5932901501655579\n",
      "Epoch 4/10, Loss: 0.6069982647895813\n",
      "Epoch 4/10, Loss: 0.6169238090515137\n",
      "Epoch 4/10, Loss: 0.6231796741485596\n",
      "Epoch 4/10, Loss: 0.629470705986023\n",
      "Epoch 5/10, Loss: 0.003520003752782941\n",
      "Epoch 5/10, Loss: 0.007870898582041264\n",
      "Epoch 5/10, Loss: 0.014081927947700024\n",
      "Epoch 5/10, Loss: 0.025594711303710938\n",
      "Epoch 5/10, Loss: 0.03694653883576393\n",
      "Epoch 5/10, Loss: 0.04159001633524895\n",
      "Epoch 5/10, Loss: 0.04947543144226074\n",
      "Epoch 5/10, Loss: 0.05398021638393402\n",
      "Epoch 5/10, Loss: 0.06711026281118393\n",
      "Epoch 5/10, Loss: 0.0723179504275322\n",
      "Epoch 5/10, Loss: 0.08162654936313629\n",
      "Epoch 5/10, Loss: 0.08917633444070816\n",
      "Epoch 5/10, Loss: 0.09453889727592468\n",
      "Epoch 5/10, Loss: 0.09829407930374146\n",
      "Epoch 5/10, Loss: 0.10402855277061462\n",
      "Epoch 5/10, Loss: 0.10881312191486359\n",
      "Epoch 5/10, Loss: 0.11398806422948837\n",
      "Epoch 5/10, Loss: 0.11912280321121216\n",
      "Epoch 5/10, Loss: 0.1254926323890686\n",
      "Epoch 5/10, Loss: 0.1353183537721634\n",
      "Epoch 5/10, Loss: 0.14155162870883942\n",
      "Epoch 5/10, Loss: 0.14712849259376526\n",
      "Epoch 5/10, Loss: 0.15444378554821014\n",
      "Epoch 5/10, Loss: 0.15994811058044434\n",
      "Epoch 5/10, Loss: 0.16204409301280975\n",
      "Epoch 5/10, Loss: 0.16743656992912292\n",
      "Epoch 5/10, Loss: 0.17199207842350006\n",
      "Epoch 5/10, Loss: 0.17850889265537262\n",
      "Epoch 5/10, Loss: 0.1838584989309311\n",
      "Epoch 5/10, Loss: 0.18945807218551636\n",
      "Epoch 5/10, Loss: 0.20086579024791718\n",
      "Epoch 5/10, Loss: 0.20835435390472412\n",
      "Epoch 5/10, Loss: 0.21626196801662445\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [25]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m     logits \u001b[38;5;241m=\u001b[39m hybrid_model(\n\u001b[0;32m     16\u001b[0m         batch_user_ids, batch_item_ids, batch_input_ids, batch_attention_mask\n\u001b[0;32m     17\u001b[0m     )\n\u001b[0;32m     18\u001b[0m     loss_value \u001b[38;5;241m=\u001b[39m loss_fn(batch_ratings, logits)\n\u001b[1;32m---> 20\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhybrid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mapply_gradients(\u001b[38;5;28mzip\u001b[39m(gradients, hybrid_model\u001b[38;5;241m.\u001b[39mtrainable_variables))\n\u001b[0;32m     23\u001b[0m epoch_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_value\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1113\u001b[0m, in \u001b[0;36mGradientTape.gradient\u001b[1;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[0;32m   1107\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1108\u001b[0m       composite_tensor_gradient\u001b[38;5;241m.\u001b[39mget_flat_tensors_for_gradients(\n\u001b[0;32m   1109\u001b[0m           output_gradients))\n\u001b[0;32m   1110\u001b[0m   output_gradients \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(x)\n\u001b[0;32m   1111\u001b[0m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[1;32m-> 1113\u001b[0m flat_grad \u001b[38;5;241m=\u001b[39m \u001b[43mimperative_grad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1114\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1115\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1116\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1117\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1118\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_persistent:\n\u001b[0;32m   1122\u001b[0m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_watched_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tape\u001b[38;5;241m.\u001b[39mwatched_variables()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[0m, in \u001b[0;36mimperative_grad\u001b[1;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     65\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m unconnected_gradients)\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:160\u001b[0m, in \u001b[0;36m_gradient_function\u001b[1;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[0;32m    158\u001b[0m     gradient_name_scope \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m forward_pass_name_scope \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    159\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(gradient_name_scope):\n\u001b[1;32m--> 160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, \u001b[38;5;241m*\u001b[39mout_grads)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1736\u001b[0m, in \u001b[0;36m_MatMulGrad\u001b[1;34m(op, grad)\u001b[0m\n\u001b[0;32m   1734\u001b[0m b \u001b[38;5;241m=\u001b[39m math_ops\u001b[38;5;241m.\u001b[39mconj(op\u001b[38;5;241m.\u001b[39minputs[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[1;32m-> 1736\u001b[0m   grad_a \u001b[38;5;241m=\u001b[39m \u001b[43mgen_math_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1737\u001b[0m   grad_b \u001b[38;5;241m=\u001b[39m gen_math_ops\u001b[38;5;241m.\u001b[39mmat_mul(a, grad, transpose_a\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6012\u001b[0m, in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   6011\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 6012\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   6013\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mMatMul\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_a\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtranspose_b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   6014\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6015\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   6016\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0.0\n",
    "\n",
    "    for batch in range(num_batches):\n",
    "        start_idx = batch * batch_size\n",
    "        end_idx = start_idx + batch_size\n",
    "\n",
    "        batch_user_ids = train_user_ids[start_idx:end_idx]\n",
    "        batch_item_ids = train_item_ids[start_idx:end_idx]\n",
    "        batch_input_ids = train_input_ids[start_idx:end_idx]\n",
    "        batch_attention_mask = train_attention_mask[start_idx:end_idx]\n",
    "        batch_ratings = train_ratings[start_idx:end_idx]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = hybrid_model(\n",
    "                batch_user_ids, batch_item_ids, batch_input_ids, batch_attention_mask\n",
    "            )\n",
    "            loss_value = loss_fn(batch_ratings, logits)\n",
    "\n",
    "        gradients = tape.gradient(loss_value, hybrid_model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, hybrid_model.trainable_variables))\n",
    "\n",
    "        epoch_loss += loss_value\n",
    "\n",
    "        # Compute average loss for the epoch\n",
    "        avg_loss = epoch_loss / num_batches\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {avg_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397fcdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47cd3a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1304930448532104\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "test_logits = hybrid_model(\n",
    "    test_user_ids, test_item_ids, test_input_ids, test_attention_mask\n",
    ")\n",
    "test_loss = loss_fn(test_ratings, test_logits)\n",
    "print(f\"Test Loss: {test_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51d71c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.277096 , 2.7689426, 4.098003 , 4.3144093, 3.4339588, 2.9514067,\n",
       "       3.6401398, 3.6433227, 3.511151 , 4.275472 , 3.4982069, 2.7214282,\n",
       "       3.431699 , 3.1523678, 4.368536 , 2.6521423, 3.471103 , 3.1395957,\n",
       "       3.0039124, 2.9170804, 3.715742 , 2.588795 , 4.757001 , 3.829666 ,\n",
       "       2.8495452, 4.786401 , 4.6477737, 2.576473 , 3.1374204, 3.3316638,\n",
       "       2.733906 , 3.8679535, 3.850675 , 3.2318513, 1.8278787, 3.404947 ,\n",
       "       3.68436  , 4.1371117, 3.1728039, 2.4653406, 2.8977911, 3.82677  ,\n",
       "       4.211941 , 3.1268196, 1.6614109, 3.5294545, 2.7360318, 2.7193382,\n",
       "       3.4139638, 3.7442453, 3.141382 , 4.0983744, 4.1111374, 3.640196 ,\n",
       "       3.435186 , 4.8202496, 3.3584359, 3.5360508, 2.9413884, 3.8973007,\n",
       "       3.055059 , 3.497141 , 4.003553 , 2.7753232, 3.6783087, 3.6472235,\n",
       "       3.0492504, 3.800766 , 2.7955573, 4.1497574, 1.8532273, 3.4746854,\n",
       "       4.952982 , 3.3740656, 4.714817 , 2.6489935, 3.6558173, 3.0110912,\n",
       "       2.5753028, 3.911787 , 2.172591 , 3.6603034, 4.044644 , 3.2248986,\n",
       "       3.5540478, 3.5205305, 3.0530045, 3.6764424, 3.5278933, 2.214268 ,\n",
       "       4.144732 , 3.7380817, 2.7652488, 4.1385565, 3.3267803, 3.6559408,\n",
       "       3.8856866, 4.0689898, 2.4147456, 3.8834774, 4.1351132, 4.335863 ,\n",
       "       3.0700192, 2.3862627, 3.3142354, 4.5863304, 3.4819193, 3.9260104,\n",
       "       2.6709003, 2.894911 , 3.1390803, 5.1092043, 3.262821 , 4.4749937,\n",
       "       3.912628 , 3.6425583, 2.6898787, 2.9228704, 3.0171685, 4.508732 ,\n",
       "       4.0931363, 3.9077342, 3.8693273, 3.4335232, 3.7362292, 3.896085 ,\n",
       "       4.378304 , 1.8721979, 4.941597 , 2.5681627, 3.8202915, 3.215811 ,\n",
       "       2.6568434, 3.1004515, 3.0182078, 3.4143064, 3.0158777, 3.7682881,\n",
       "       3.5468018, 4.0117073, 3.1774535, 3.8304338, 4.371372 , 4.457328 ,\n",
       "       4.1234884, 4.314616 , 3.493714 , 2.3798761, 2.913418 , 3.1534336,\n",
       "       3.6305304, 3.8061085, 3.666547 , 3.0303905, 3.720042 , 2.62202  ,\n",
       "       3.223913 , 3.740413 , 3.693633 , 3.7795038, 2.5864284, 3.116402 ,\n",
       "       2.5833776, 3.5946314, 3.1541939, 3.3406591, 4.7453175, 2.9487402,\n",
       "       2.7822864, 2.024757 , 2.7653916, 3.0992262, 2.7652724, 2.9115508,\n",
       "       1.7705262, 3.1574917, 3.9914281, 4.0133905, 3.7477605, 3.8586128,\n",
       "       2.8795383, 3.7765439, 3.5547495, 2.6105735, 3.4465163, 3.2061732,\n",
       "       2.8294709, 4.1735764, 2.5994217, 3.0032492, 3.3582497, 2.764498 ,\n",
       "       2.566219 , 4.175803 , 3.9382758, 2.8684254, 2.7572315, 3.6795707,\n",
       "       3.3748899, 2.9217882, 3.9608743, 2.898964 , 3.41629  , 4.5506525,\n",
       "       2.7891047, 3.537051 , 3.9544404, 4.5864   , 4.566986 , 2.7844186,\n",
       "       3.4046767, 2.5591414, 4.572709 , 2.643232 , 3.4633682, 3.5916913,\n",
       "       2.590291 , 4.610215 , 2.8321614, 3.5927756, 3.1677797, 5.145562 ,\n",
       "       2.6052282, 4.215285 , 3.7278984, 2.7430375, 4.320672 , 4.600045 ,\n",
       "       3.5837898, 4.118387 , 4.5972676, 4.445892 , 3.7300658, 3.2782705,\n",
       "       5.017043 , 4.4030075, 4.982005 , 3.003352 , 3.428048 , 2.8281443,\n",
       "       3.072204 , 3.3373675, 3.7383425, 3.3337588, 3.7450798, 3.420004 ,\n",
       "       2.448851 , 3.822346 , 3.5129962, 3.0790184, 4.704726 , 3.6189096,\n",
       "       3.7796686, 3.1077669, 2.5528753, 3.2961082, 2.4490135, 3.7797573,\n",
       "       2.933416 , 4.0036144, 2.7685215, 2.2432282, 3.6521842, 4.1439586,\n",
       "       2.6190474, 3.6514993, 3.694068 , 2.8436315, 4.1578994, 4.4836836,\n",
       "       3.4772127, 4.6473446, 2.7697961, 3.6866238, 3.6371562, 4.476224 ,\n",
       "       4.5878515, 2.7518523, 3.3323278, 3.1384013, 2.6784708, 3.486999 ,\n",
       "       3.2231526, 2.9226954, 4.22367  , 4.12799  , 2.8639534, 3.0274124,\n",
       "       2.546573 , 3.382371 , 3.678525 , 2.7266886, 3.6831183, 3.7151318,\n",
       "       4.2132173, 3.3304307, 3.05216  , 3.708621 , 3.6978915, 3.28298  ,\n",
       "       4.4491796, 2.6485727, 2.7834363, 2.8052561, 2.6803644, 2.1938586,\n",
       "       2.9339406, 3.4065478, 3.864206 , 3.8333352, 2.8435988, 3.9636738,\n",
       "       2.6504738, 3.9724438, 2.9385498, 2.5365965, 3.996734 , 3.2832873,\n",
       "       4.2571583, 4.4272537, 2.6374142, 4.0151787, 2.6717732, 3.7322795,\n",
       "       3.6365712, 2.7461886, 3.2990925, 3.8855877, 3.2417848, 3.8186495,\n",
       "       3.4711578, 3.5430067, 3.376498 , 3.7093256, 2.9876087, 3.1710799,\n",
       "       4.573283 , 4.688374 , 4.3647738, 3.843364 , 2.4670818, 3.5878403,\n",
       "       3.7617824, 3.317395 , 3.609596 , 3.7589452, 4.938261 , 2.396241 ,\n",
       "       2.4857476, 3.5505657, 2.5539715, 2.7105587, 3.5228646, 3.2144563,\n",
       "       3.5488446, 3.9683049, 3.1588254, 3.5265248, 3.6507118, 2.6312091,\n",
       "       4.65957  , 3.5655744, 3.522829 , 4.2356052, 3.4139745, 3.1221485,\n",
       "       4.867983 , 2.580407 , 3.6020105, 3.689916 , 5.0202646, 3.206958 ,\n",
       "       5.2458754, 3.5522993, 2.5457585, 3.3867462, 3.353103 , 5.197753 ,\n",
       "       4.8803816, 3.0509703, 2.8030858, 2.8784053, 3.7155292, 3.2986403,\n",
       "       4.201628 , 4.0180783, 2.9254382, 3.9109297, 2.8297937, 3.5189126,\n",
       "       3.6476696, 2.6548574, 2.9302964, 3.5821984, 3.9863102, 3.8177173,\n",
       "       3.7821155, 3.63741  , 2.9014328, 4.254813 , 2.8796613, 3.8295307,\n",
       "       3.857166 , 2.8879306, 3.793956 , 2.6477883, 3.5019848, 3.2859151,\n",
       "       2.2021554, 2.465482 , 4.4182897, 4.3947477, 3.5743282, 4.8338947,\n",
       "       3.132055 , 3.62339  , 3.3895874, 3.3715518, 4.5172133, 3.76067  ,\n",
       "       3.805289 , 2.2015083, 4.459069 , 4.18091  , 4.9906626, 3.753445 ,\n",
       "       3.5691695, 2.7247071, 3.483988 , 3.5732062, 2.9909322, 2.325608 ,\n",
       "       3.7620294, 3.3735507, 3.180961 , 4.5538855, 2.8089163, 1.7723116,\n",
       "       1.8345275, 3.2057977, 2.7472036, 4.095977 , 3.0942814, 2.4082386,\n",
       "       2.6930192, 2.3864899, 3.5543826, 2.5061274, 4.7407436, 4.0210776,\n",
       "       3.7830827, 3.11776  , 2.650843 , 3.609485 , 3.389311 , 3.3943026,\n",
       "       4.321231 , 2.922219 , 3.8254876, 3.5402846, 3.7257814, 3.5103729,\n",
       "       3.2965806, 3.2653801, 2.5567782, 3.091033 , 4.019615 , 3.9240415,\n",
       "       2.4754338, 2.979647 , 2.7125342, 1.8588744, 4.1397104, 3.388581 ,\n",
       "       3.9580941, 4.1919703, 4.825596 , 3.3730137, 4.237772 , 3.3759406,\n",
       "       4.9897428, 3.2212942, 2.6701443, 2.7361279, 3.4259336, 3.7243793,\n",
       "       3.333292 , 3.1366782, 3.0716026, 3.695705 , 4.5779214, 2.7940361,\n",
       "       3.3024106, 3.000448 , 5.1425686, 2.6581542, 4.3854327, 3.6498096,\n",
       "       2.9051821, 3.6297352, 2.5490046, 2.6773527, 4.115822 , 3.4424398,\n",
       "       3.6593082, 4.232638 , 4.869252 , 3.9491735, 2.6408029, 3.1844366,\n",
       "       2.4562118, 2.9713914, 2.514808 , 3.7514539, 3.33792  , 2.5749886,\n",
       "       3.5820715, 3.6388826, 2.7832444, 3.767345 , 3.1967762, 2.9773154,\n",
       "       2.665252 , 4.3079576, 4.0159545, 1.602453 , 4.1507015, 4.0155344,\n",
       "       3.411652 , 2.7280319, 5.076471 , 3.404777 , 3.3309267, 3.4506505,\n",
       "       3.2444031, 4.052885 , 4.138718 , 3.4416568, 2.862231 , 3.5049655,\n",
       "       3.5459015, 3.5978165, 3.8220675, 5.250846 , 3.4886491, 2.6313999,\n",
       "       4.2264957, 4.487345 , 4.971178 , 3.3758762, 2.7495468, 3.8983493,\n",
       "       3.6955545, 3.9879365, 2.6376688, 2.3434489, 5.0122337, 3.7746437,\n",
       "       4.9196353, 2.494497 , 4.6269836, 2.8084562, 3.5444353, 3.7064111,\n",
       "       3.5491862, 3.7454927, 3.5873954, 3.0873582, 2.9168818, 2.4785175,\n",
       "       3.7916377, 3.5002944, 3.8217852, 3.3395476, 2.959293 , 4.2509723,\n",
       "       3.1954644, 4.1289496, 3.3732374, 3.4431965, 4.464052 , 2.6414926,\n",
       "       3.693987 , 3.058149 , 4.173586 , 3.6623416, 3.8813899, 3.1125119,\n",
       "       4.122409 , 3.2611096, 2.6805325, 2.7100728, 3.3344266, 2.967016 ,\n",
       "       3.3741353, 4.1665344], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_logits.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1781cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
